{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b02429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import predict\n",
    "from utils import init_logger, load_tokenizer, get_labels, MODEL_CLASSES\n",
    "import easydict\n",
    "import re\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "WEEKDAY = {0:\"월요일\",1:\"화요일\",2:\"수요일\",3:\"목요일\",4:\"금요일\",5:\"토요일\",6:\"일요일\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9044945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFirstSecond(arr):\n",
    "    second = first = -float('inf')\n",
    "    second_i = first_i = 0\n",
    "    for i,n in enumerate(arr):\n",
    "        if n > first:\n",
    "            second = first\n",
    "            first = n\n",
    "            second_i = first_i\n",
    "            first_i = i\n",
    "        elif second < n < first:\n",
    "            second = n\n",
    "            second_i = i\n",
    "    return first_i,second_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e841af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config = easydict.EasyDict({\n",
    "    \"input_file\":\"tel6.txt\",\n",
    "    \"output_file\":\"tel6_out.txt\",\n",
    "    \"model_dir\":\"./model\",\n",
    "    \"batch_size\":32,\n",
    "    \"no_cuda\":\"store_true\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedea8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_file': 'tel6.txt',\n",
       " 'output_file': 'tel6_out.txt',\n",
       " 'model_dir': './model',\n",
       " 'batch_size': 32,\n",
       " 'no_cuda': 'store_true'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcff17",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71685b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = predict.get_args(pred_config)\n",
    "device = predict.get_device(pred_config)\n",
    "model = predict.load_model(pred_config, args, device)\n",
    "label_lst = get_labels(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8013b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_label_id = torch.nn.CrossEntropyLoss().ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6f525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = load_tokenizer(args)\n",
    "tokenizer = MODEL_CLASSES[args.model_type][2].from_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32185ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='./tokenizer', vocab_size=8002, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1d7da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_epsilon=1e-08, data_dir='./data', do_eval=True, do_train=True, eval_batch_size=64, gradient_accumulation_steps=1, label_file='label.txt', learning_rate=5e-05, logging_steps=1000, max_grad_norm=1.0, max_seq_len=50, max_steps=-1, model_dir='./model', model_name_or_path='monologg/kobert', model_type='kobert', no_cuda=False, num_train_epochs=20.0, pred_dir='./preds', save_steps=1000, seed=42, task='naver-ner', test_file='test.tsv', train_batch_size=32, train_file='train.tsv', warmup_steps=0, weight_decay=0.0, write_pred=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b171c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config[\"input_file\"] = \"./suggestion_test_data/tel4.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6e4e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8074ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = predict.read_input_file(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a07f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = predict.convert_input_file_to_tensor_dataset(lines, pred_config, args, tokenizer, pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8849a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequentialSampler(dataset)\n",
    "data_loader = DataLoader(dataset, sampler=sampler, batch_size=pred_config.batch_size)\n",
    "all_slot_label_mask = None\n",
    "preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f302c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0],\n",
    "                      \"attention_mask\": batch[1],\n",
    "                      \"labels\": None}\n",
    "            if args.model_type != \"distilkobert\":\n",
    "                inputs[\"token_type_ids\"] = batch[2]\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                all_slot_label_mask = batch[3].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                all_slot_label_mask = np.append(all_slot_label_mask, batch[3].detach().cpu().numpy(), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1968f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pred = []\n",
    "second_pred = []\n",
    "for i in range(preds.shape[0]):\n",
    "    first_pred.append([])\n",
    "    second_pred.append([])\n",
    "    for j in range(preds.shape[1]):\n",
    "        first,second = findFirstSecond(preds[i][j])\n",
    "        first_pred[i].append(first)\n",
    "        second_pred[i].append(second)\n",
    "first_pred = np.array(first_pred)\n",
    "second_pred = np.array(second_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacaefb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_pred[12][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0b5586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 29)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findFirstSecond(preds[12][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a749b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,2번째 큰 확률 다 반영\n",
    "\n",
    "slot_label_map = {i: label for i, label in enumerate(label_lst)}\n",
    "preds_list = [[] for _ in range(first_pred.shape[0])]\n",
    "for_loc_list = [[] for _ in range(first_pred.shape[0])]\n",
    "\n",
    "for i in range(first_pred.shape[0]):\n",
    "    for j in range(first_pred.shape[1]):\n",
    "        if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "            if first_pred[i][j] not in [16,17] and second_pred[i][j] in [16,17]:\n",
    "                preds_list[i].append(slot_label_map[second_pred[i][j]])\n",
    "            else:\n",
    "                preds_list[i].append(slot_label_map[first_pred[i][j]])\n",
    "                \n",
    "            if first_pred[i][j] not in [8,9,10,11,14,15,16,17] and second_pred[i][j] in [8,9,10,11,16,17]:\n",
    "                for_loc_list[i].append(slot_label_map[second_pred[i][j]])\n",
    "                if i==12 and j ==0:\n",
    "                    print(slot_label_map[first_pred[i][j]])\n",
    "            else:\n",
    "                for_loc_list[i].append(slot_label_map[first_pred[i][j]])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fca3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "date_time_loc = {}\n",
    "loc = []\n",
    "second_loc = []\n",
    "for i,wp in enumerate(zip(lines, preds_list)):\n",
    "            date_time_loc[i] = []\n",
    "            for j,(word, p) in enumerate(zip(wp[0], wp[1])):\n",
    "                #B-I를 같은 리스트에 담아서 연결성 up    ex) 내일 오전 어떠세요? 10시 좋아요\n",
    "                if p == 'DAT-B':\n",
    "                    date.append(word)\n",
    "                elif p == 'DAT-I':\n",
    "                    if \"뒤\" in word or \"후\" in word:\n",
    "                        date[-1] = date[-1]+word\n",
    "                    else:\n",
    "                        date.append(word)\n",
    "                elif p == 'TIM-B':\n",
    "                    time.append(word)\n",
    "                elif p == 'TIM-I':\n",
    "                    if \"뒤\" in word or \"후\" in word:\n",
    "                        time[-1] = time[-1]+word\n",
    "                    else:\n",
    "                        time.append(word)\n",
    "                elif p == 'LOC-B':\n",
    "                    if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "                        loc[-1] = loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        loc.append(word)\n",
    "                elif p == 'LOC-I':\n",
    "                    loc[-1] = loc[-1] + \" \"+ word\n",
    "                elif p == 'ORG-B':\n",
    "                    if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "                        loc[-1] = loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        loc.append(word)\n",
    "                elif p == 'ORG-I':\n",
    "                    loc[-1] = loc[-1] + \" \"+ word\n",
    "                elif (p == 'NUM-B'or p == 'NUM-I')and \"시\" in word:\n",
    "                    time.append(word)\n",
    "                elif \"반\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']:\n",
    "                    time.append(word)\n",
    "                elif \"뒤\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']:\n",
    "                    time[-1] = time[-1]+word\n",
    "                elif \"후\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']:\n",
    "                    time[-1] = time[-1]+word\n",
    "                else:\n",
    "                    continue\n",
    "                date_time_loc[i].append(word)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eef7d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O'],\n",
       " [],\n",
       " ['NUM-B'],\n",
       " [],\n",
       " ['CVL-B', 'O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'NUM-B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " ['O', 'DAT-B', 'DAT-I', 'O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['DAT-B', 'TIM-B', 'DAT-B', 'O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'DAT-B', 'TIM-B', 'TIM-I', 'O'],\n",
       " [],\n",
       " ['TIM-B', 'O'],\n",
       " [],\n",
       " ['DAT-B', 'O', 'TIM-B', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O', 'DAT-B', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O'],\n",
       " [],\n",
       " ['O', 'O', 'O', 'DAT-B', 'TIM-B', 'O'],\n",
       " [],\n",
       " ['O'],\n",
       " [],\n",
       " ['O', 'O', 'DAT-B', 'DAT-B', 'O', 'O', 'DAT-B', 'DAT-B', 'TIM-B', 'O'],\n",
       " [],\n",
       " ['TIM-B', 'O', 'TIM-B', 'TIM-I', 'O'],\n",
       " [],\n",
       " ['O'],\n",
       " [],\n",
       " ['O', 'O', 'DAT-B', 'O']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7064a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "year = now.year\n",
    "month = now.month\n",
    "day = now.day\n",
    "date_fix = 0\n",
    "hour = now.hour\n",
    "hour_sub = 0   # 없으면 0 오전 1 오후 2\n",
    "hour_back = 0\n",
    "hour_flag = 0\n",
    "minute = 0\n",
    "minute_sub = \"\"\n",
    "weekday = now.weekday()\n",
    "next_week = 0\n",
    "next_day = 0\n",
    "isWeekday= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d748cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time calculate\n",
    "for t in time:\n",
    "    if \"오전\" in t:\n",
    "        hour_sub = 1\n",
    "    elif \"오후\" in t:\n",
    "        hour_sub = 2\n",
    "    elif \"뒤\" in t:\n",
    "        hour_back = re.sub(r'[^0-9]', '', t)\n",
    "    elif \"후\" in t:\n",
    "        hour_back = re.sub(r'[^0-9]', '', t)\n",
    "    elif \"시\" in t:\n",
    "        if re.search('\\d',t):\n",
    "            hour = re.sub(r'[^0-9]', '', t)  \n",
    "        elif \"한시\" in t:\n",
    "            hour = 1\n",
    "            hour_flag = 1\n",
    "        elif \"두시\" in t :\n",
    "            hour = 2\n",
    "            hour_flag = 1\n",
    "        elif \"세시\" in t :\n",
    "            hour = 3\n",
    "            hour_flag = 1\n",
    "        elif \"네시\" in t:\n",
    "            hour = 4\n",
    "            hour_flag = 1\n",
    "        elif \"다섯시\" in t :\n",
    "            hour = 5\n",
    "            hour_flag = 1\n",
    "        elif \"여섯시\" in t:\n",
    "            hour = 6\n",
    "            hour_flag = 1\n",
    "        elif \"일곱시\" in t :\n",
    "            hour = 7\n",
    "            hour_flag = 1\n",
    "        elif \"여덜시\" in t :\n",
    "            hour = 8\n",
    "        elif \"아홉시\" in t:\n",
    "            hour = 9\n",
    "        elif \"열시\" in t:\n",
    "            hour = 10\n",
    "        elif \"열한시\" in t:\n",
    "            hour = 11\n",
    "        elif \"열두시\" in t:\n",
    "            hour = 12\n",
    "    elif \"분\" in t:\n",
    "        minute = re.sub(r'[^0-9]', '', t)\n",
    "    elif \"반\" in t:\n",
    "        minute = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02f5b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화해서 조사인지 확인하고 조사라면 떼어내기\n",
    "# 근데 이게 경기도 같은거에서 도가 빠지는지 확인.....\n",
    "# for i in range(20):\n",
    "#     print(tokenizer.tokenize(lines[51][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15015b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in date:\n",
    "    if \"다음주\" in d or \"다음 주\" in d:\n",
    "        next_week = 1\n",
    "    elif \"이번주\" in d:\n",
    "        next_week = 0\n",
    "    elif \"내일\" in d and next_day == 0:\n",
    "        day += 1\n",
    "        weekday += 1\n",
    "        next_day = 1\n",
    "    elif \"오늘\" in d:\n",
    "        day = now.day\n",
    "        weekday = now.weekday()\n",
    "    elif \"월요일\" in d:\n",
    "        promise_week = 0\n",
    "        isWeekday = 1\n",
    "    elif \"화요일\" in d:\n",
    "        promise_week = 1\n",
    "        isWeekday = 1\n",
    "    elif \"수요일\" in d :\n",
    "        promise_week = 2\n",
    "        isWeekday = 1\n",
    "    elif \"목요일\" in d: \n",
    "        promise_week = 3\n",
    "        isWeekday = 1\n",
    "    elif \"금요일\" in d:\n",
    "        promise_week = 4\n",
    "        isWeekday = 1\n",
    "    elif \"토요일\" in d:\n",
    "        promise_week = 5\n",
    "        isWeekday = 1\n",
    "    elif \"일요일\" in d:\n",
    "        promise_week = 5\n",
    "        isWeekday = 1\n",
    "    elif \"일\" in d and re.search('\\d',d):\n",
    "        day = re.sub(r'[^0-9]', '', d)\n",
    "        date_fix = 1\n",
    "    elif \"월\" in d and re.search('\\d',d):\n",
    "        month = re.sub(r'[^0-9]', '', d)\n",
    "    elif \"년\" in d and re.search('\\d',d):\n",
    "        year = re.sub(r'[^0-9]', '', d)\n",
    "        if year < 2023:\n",
    "            year = 2023\n",
    "\n",
    "#대화에 요일이 있을 때\n",
    "if isWeekday==1:\n",
    "    if weekday > promise_week or next_week == 1:\n",
    "        day = int(now.day) + promise_week - weekday + 7\n",
    "    else:\n",
    "        day = int(now.day) + promise_week - weekday\n",
    "    weekday = promise_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cae9d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first확률에서 약속장소가 없을경우 두번때 확률까지 탐색\n",
    "second_loc = []\n",
    "if loc == []:\n",
    "    date_time_loc = {}\n",
    "    for i,wp in enumerate(zip(lines, for_loc_list)):\n",
    "            date_time_loc[i] = []\n",
    "            for j,(word, p) in enumerate(zip(wp[0], wp[1])):\n",
    "                if p in ['DAT-B','DAT-I','TIM-B','TIM-I'] or ((p == 'NUM-B'or p == 'NUM-I')and \"시\" in word) or (\"반\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']):\n",
    "                    date_time_loc[i].append(word)\n",
    "                    continue\n",
    "                elif p == 'LOC-B':\n",
    "                    if for_loc_list[i][j-1] in ['ORG-B','LOC-B'] and second_loc != []:\n",
    "                        second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        second_loc.append(word)\n",
    "                elif p == 'LOC-I':\n",
    "                    second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "                elif p == 'ORG-B':\n",
    "                    if for_loc_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "                        second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        second_loc.append(word)\n",
    "                elif p == 'ORG-I':\n",
    "                    second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "                else:\n",
    "                    continue\n",
    "                date_time_loc[i].append(word)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46c36f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오전이나', '오전', '11시', '11시', '11시에', '11시에', '3시는', '3시', '1시간뒤는']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "802ab737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if day == now.day:\n",
    "    if int(hour) < now.hour:\n",
    "        hour = int(hour) + 12\n",
    "if next_day == 1 :\n",
    "    if 0 < int(hour) < 6:\n",
    "        hour = int(hour) + 12\n",
    "weekday = weekday % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21a5144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = -1\n",
    "max = -1\n",
    "for i in range(len(date_time_loc)):\n",
    "    if max <= len(date_time_loc[i]):\n",
    "        max = len(date_time_loc[i])\n",
    "        max_i = i\n",
    "\n",
    "#location processing\n",
    "ignore = ['에서','라는']\n",
    "if loc == []:\n",
    "    location = \"미정\"\n",
    "    for i in range(len(for_loc_list[max_i])):\n",
    "        if for_loc_list[max_i][i] in ['ORG-B','LOC-B']:\n",
    "            location = lines[max_i][i]\n",
    "else:\n",
    "    location = loc[-1]\n",
    "for s in ignore:\n",
    "    location = re.sub(s,\"\",location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "973bab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주요 통화 내용 : 아아 저 다음주 화요일은 안될것같고 혹시 이번주 금요일 3시는 어떠신가요 \n"
     ]
    }
   ],
   "source": [
    "print(\"주요 통화 내용 : {} \".format(' '.join(s for s in lines[max_i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91c78cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "약속 장소 : 미정 , 약속 시간 : 2023년 2월 10일  3시 0분 (금요일)\n"
     ]
    }
   ],
   "source": [
    "print(\"약속 장소 : {} , 약속 시간 : {}년 {}월 {}일  {}시 {}분 ({})\".format(location,year,month,day,hour,minute,WEEKDAY[weekday]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d265240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: ['다음', '주'],\n",
       " 8: [],\n",
       " 9: ['화요일', '오전이나', '수요일', '중이'],\n",
       " 10: [],\n",
       " 11: ['화수', '화요일', '오전', '11시'],\n",
       " 12: [],\n",
       " 13: ['11시'],\n",
       " 14: [],\n",
       " 15: ['오는', '11시에'],\n",
       " 16: [],\n",
       " 17: [],\n",
       " 18: [],\n",
       " 19: ['26일까지'],\n",
       " 20: [],\n",
       " 21: ['네네네'],\n",
       " 22: [],\n",
       " 23: ['화요일날', '11시에'],\n",
       " 24: [],\n",
       " 25: [],\n",
       " 26: [],\n",
       " 27: ['다음주', '화요일은', '이번주', '금요일', '3시는'],\n",
       " 28: [],\n",
       " 29: ['3시', '1시간', '뒤는'],\n",
       " 30: [],\n",
       " 31: [],\n",
       " 32: [],\n",
       " 33: ['금요일에']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d43374fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee44b42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스타벅스가에서'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = \"스타벅스가에서\"\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3428ef48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스타벅스가에서'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142b3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daa274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b295ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "# Extract time information using regular expressions\n",
    "def extract_time(text):\n",
    "    time_pattern = re.compile(r'\\d{1,2}:\\d{1,2}')\n",
    "    match = re.search(time_pattern, text)\n",
    "    if match:\n",
    "        time_str = match.group()\n",
    "        hour, minute = map(int, time_str.split(':'))\n",
    "        return datetime.time(hour, minute)\n",
    "    return None\n",
    "\n",
    "# Calculate the time difference between the current time and appointment time\n",
    "def calculate_time_difference(appointment_time):\n",
    "    now = datetime.datetime.now().time()\n",
    "    appointment_datetime = datetime.datetime.combine(datetime.datetime.today(), appointment_time)\n",
    "    difference = appointment_datetime - datetime.datetime.now()\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "text = \"My appointment is at 10:30 on tuesday.\"\n",
    "appointment_time = extract_time(text)\n",
    "if appointment_time:\n",
    "    time_difference = calculate_time_difference(appointment_time)\n",
    "    print(f\"The appointment is in {time_difference}.\")\n",
    "else:\n",
    "    print(\"Unable to extract appointment time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ccfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
