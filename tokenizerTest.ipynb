{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2113895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import predict\n",
    "from utils import init_logger, load_tokenizer, get_labels\n",
    "import easydict\n",
    "import re\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "WEEKDAY = {0:\"월요일\",1:\"화요일\",2:\"수요일\",3:\"목요일\",4:\"금요일\",5:\"토요일\",6:\"일요일\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b215a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFirstSecond(arr):\n",
    "    second = first = -float('inf')\n",
    "    second_i = first_i = 0\n",
    "    for i,n in enumerate(arr):\n",
    "        if n > first:\n",
    "            second = first\n",
    "            first = n\n",
    "            second_i = first_i\n",
    "            first_i = i\n",
    "        elif second < n < first:\n",
    "            second = n\n",
    "            second_i = i\n",
    "    return first_i,second_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7748fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config = easydict.EasyDict({\n",
    "    \"input_file\":\"tel6.txt\",\n",
    "    \"output_file\":\"tel6_out.txt\",\n",
    "    \"model_dir\":\"./model\",\n",
    "    \"batch_size\":32,\n",
    "    \"no_cuda\":\"store_true\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5334422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_file': 'tel6.txt',\n",
       " 'output_file': 'tel6_out.txt',\n",
       " 'model_dir': './model',\n",
       " 'batch_size': 32,\n",
       " 'no_cuda': 'store_true'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26809419",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03483863",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = predict.get_args(pred_config)\n",
    "device = predict.get_device(pred_config)\n",
    "model = predict.load_model(pred_config, args, device)\n",
    "label_lst = get_labels(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b9ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_label_id = torch.nn.CrossEntropyLoss().ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d9d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed4a227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4a63c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='./tokenizer', vocab_size=8002, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.from_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2db4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_epsilon=1e-08, data_dir='./data', do_eval=True, do_train=True, eval_batch_size=64, gradient_accumulation_steps=1, label_file='label.txt', learning_rate=5e-05, logging_steps=1000, max_grad_norm=1.0, max_seq_len=50, max_steps=-1, model_dir='./model', model_name_or_path='monologg/kobert', model_type='kobert', no_cuda=False, num_train_epochs=20.0, pred_dir='./preds', save_steps=1000, seed=42, task='naver-ner', test_file='test.tsv', train_batch_size=32, train_file='train.tsv', warmup_steps=0, weight_decay=0.0, write_pred=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8372a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config[\"input_file\"] = \"tel5.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3e357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ee387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = predict.read_input_file(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0e6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = predict.convert_input_file_to_tensor_dataset(lines, pred_config, args, tokenizer, pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9a641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequentialSampler(dataset)\n",
    "data_loader = DataLoader(dataset, sampler=sampler, batch_size=pred_config.batch_size)\n",
    "all_slot_label_mask = None\n",
    "preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c97b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0],\n",
    "                      \"attention_mask\": batch[1],\n",
    "                      \"labels\": None}\n",
    "            if args.model_type != \"distilkobert\":\n",
    "                inputs[\"token_type_ids\"] = batch[2]\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                all_slot_label_mask = batch[3].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                all_slot_label_mask = np.append(all_slot_label_mask, batch[3].detach().cpu().numpy(), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd66f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pred = []\n",
    "second_pred = []\n",
    "for i in range(preds.shape[0]):\n",
    "    first_pred.append([])\n",
    "    second_pred.append([])\n",
    "    for j in range(preds.shape[1]):\n",
    "        first,second = findFirstSecond(preds[i][j])\n",
    "        first_pred[i].append(first)\n",
    "        second_pred[i].append(second)\n",
    "first_pred = np.array(first_pred)\n",
    "second_pred = np.array(second_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5cce39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최대만 찾기\n",
    "\n",
    "# slot_label_map = {i: label for i, label in enumerate(label_lst)}\n",
    "# preds_list = [[] for _ in range(first_pred.shape[0])]\n",
    "\n",
    "# for i in range(first_pred.shape[0]):\n",
    "#     for j in range(first_pred.shape[1]):\n",
    "#         if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "#             preds_list[i].append(slot_label_map[first_pred[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a1124c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째만 찾기\n",
    "\n",
    "# slot_label_map = {i: label for i, label in enumerate(label_lst)}\n",
    "# preds_list = [[] for _ in range(second_pred.shape[0])]\n",
    "\n",
    "# for i in range(second_pred.shape[0]):\n",
    "#     for j in range(second_pred.shape[1]):\n",
    "#         if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "#             preds_list[i].append(slot_label_map[second_pred[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fd7c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,2번째 큰 확률 다 반영\n",
    "\n",
    "slot_label_map = {i: label for i, label in enumerate(label_lst)}\n",
    "preds_list = [[] for _ in range(first_pred.shape[0])]\n",
    "for_loc_list = [[] for _ in range(first_pred.shape[0])]\n",
    "\n",
    "for i in range(first_pred.shape[0]):\n",
    "    for j in range(first_pred.shape[1]):\n",
    "        if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "            if first_pred[i][j] not in [16,17] and second_pred[i][j] in [16,17]:\n",
    "                preds_list[i].append(slot_label_map[second_pred[i][j]])\n",
    "            else:\n",
    "                preds_list[i].append(slot_label_map[first_pred[i][j]])\n",
    "                \n",
    "            if first_pred[i][j] not in [8,9,10,11] and second_pred[i][j] in [8,9,10,11]:\n",
    "                for_loc_list[i].append(slot_label_map[second_pred[i][j]])\n",
    "            else:\n",
    "                for_loc_list[i].append(slot_label_map[first_pred[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5576391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'ORG-B', 'ORG-B', 'O', 'PER-B', 'CVL-B', 'O'],\n",
       " ['O', 'O', 'DAT-B', 'O', 'NUM-B', 'NUM-I', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O',\n",
       "  'DAT-B',\n",
       "  'TIM-B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'NUM-B',\n",
       "  'NUM-I',\n",
       "  'O',\n",
       "  'O'],\n",
       " [],\n",
       " ['O', 'DAT-B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O'],\n",
       " [],\n",
       " ['DAT-B', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O',\n",
       "  'DAT-B',\n",
       "  'TIM-B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'CVL-B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " ['O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O'],\n",
       " [],\n",
       " ['NUM-B', 'NUM-I', 'NUM-B', 'NUM-B', 'NUM-I', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " [],\n",
       " ['O', 'O'],\n",
       " [],\n",
       " ['O', 'O']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e910ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "date_time = {}\n",
    "loc = []\n",
    "second_loc = []\n",
    "for i,wp in enumerate(zip(lines, preds_list)):\n",
    "            date_time[i] = []\n",
    "            for j,(word, p) in enumerate(zip(wp[0], wp[1])):\n",
    "                #B-I를 같은 리스트에 담아서 연결성 up    ex) 내일 오전 어떠세요? 10시 좋아요\n",
    "                if p == 'DAT-B':\n",
    "                    date.append(word)\n",
    "                    date_time[i].append(word)\n",
    "                elif p == 'DAT-I':\n",
    "                    date.append(word)\n",
    "                    date_time[i].append(word)\n",
    "                elif p == 'TIM-B':\n",
    "                    time.append(word)\n",
    "                    date_time[i].append(word)\n",
    "                elif p == 'TIM-I':\n",
    "                    time.append(word)\n",
    "                    date_time[i].append(word)\n",
    "                elif p == 'LOC-B':\n",
    "                    date_time[i].append(word)\n",
    "                    if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "                        loc[-1] = loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        loc.append(word)\n",
    "                elif p == 'LOC-I':\n",
    "                    date_time[i].append(word)\n",
    "                    loc[-1] = loc[-1] + \" \"+ word\n",
    "                elif p == 'ORG-B':\n",
    "                    date_time[i].append(word)\n",
    "                    if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "                        loc[-1] = loc[-1] + \" \"+ word\n",
    "                    else:\n",
    "                        loc.append(word)\n",
    "                elif p == 'ORG-I':\n",
    "                    date_time[i].append(word)\n",
    "                    loc[-1] = loc[-1] + \" \"+ word\n",
    "                elif (p == 'NUM-B'or p == 'NUM-I')and \"시\" in word:\n",
    "                    time.append(word)\n",
    "                    date_time[i].append(word)\n",
    "                elif \"반\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']:\n",
    "                    date_time[i].append(word)\n",
    "                    time.append(word)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "677d71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "year = now.year\n",
    "month = now.month\n",
    "day = now.day\n",
    "date_fix = 0\n",
    "hour = now.hour\n",
    "hour_sub = 0   # 없으면 0 오전 1 오후 2\n",
    "hour_back = 0\n",
    "hour_flag = 0\n",
    "minute = 0\n",
    "minute_sub = \"\"\n",
    "weekday = now.weekday()\n",
    "next_week = 0\n",
    "next_day = 0\n",
    "isWeekday= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f67a868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in time:\n",
    "    if \"오전\" in t:\n",
    "        hour_sub = 1\n",
    "    elif \"오후\" in t:\n",
    "        hour_sub = 2\n",
    "    elif \"뒤\" in t:\n",
    "        hour_back = re.sub(r'[^0-9]', '', t)\n",
    "        minute = now.minute\n",
    "    elif \"후에\" in t:\n",
    "        hour_back = re.sub(r'[^0-9]', '', t)\n",
    "        minute = now.minute\n",
    "    elif \"시\" in t:\n",
    "        if re.search('\\d',t):\n",
    "            hour = re.sub(r'[^0-9]', '', t)  \n",
    "        elif \"한시\" in t:\n",
    "            hour = 1\n",
    "            hour_flag = 1\n",
    "        elif \"두시\" in t :\n",
    "            hour = 2\n",
    "            hour_flag = 1\n",
    "        elif \"세시\" in t :\n",
    "            hour = 3\n",
    "            hour_flag = 1\n",
    "        elif \"네시\" in t:\n",
    "            hour = 4\n",
    "            hour_flag = 1\n",
    "        elif \"다섯시\" in t :\n",
    "            hour = 5\n",
    "            hour_flag = 1\n",
    "        elif \"여섯시\" in t:\n",
    "            hour = 6\n",
    "            hour_flag = 1\n",
    "        elif \"일곱시\" in t :\n",
    "            hour = 7\n",
    "            hour_flag = 1\n",
    "        elif \"여덜시\" in t :\n",
    "            hour = 8\n",
    "        elif \"아홉시\" in t:\n",
    "            hour = 9\n",
    "        elif \"열시\" in t:\n",
    "            hour = 10\n",
    "        elif \"열한시\" in t:\n",
    "            hour = 11\n",
    "        elif \"열두시\" in t:\n",
    "            hour = 12\n",
    "    elif \"분\" in t:\n",
    "        minute = re.sub(r'[^0-9]', '', t)\n",
    "    elif \"반\" in t:\n",
    "        minute = 30\n",
    "\n",
    "if hour_sub == 2 and hour_flag == 1:\n",
    "    hour += 12\n",
    "if hour_back != 0:\n",
    "    hour += hour_back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e36892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화해서 조사인지 확인하고 조사라면 떼어내기\n",
    "# 근데 이게 경기도 같은거에서 도가 빠지는지 확인.....\n",
    "# for i in range(20):\n",
    "#     print(tokenizer.tokenize(lines[51][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c440bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in date:\n",
    "    if \"다음주\" in d or \"다음 주\" in d:\n",
    "        next_week = 1\n",
    "    elif \"이번주\" in d:\n",
    "        next_week = 0\n",
    "    elif \"내일\" in d and next_day == 0:\n",
    "        day += 1\n",
    "        weekday += 1\n",
    "        next_day = 1\n",
    "    elif \"오늘\" in d:\n",
    "        day = now.day\n",
    "        weekday = now.weekday()\n",
    "    elif \"월요일\" in d:\n",
    "        promise_week = 0\n",
    "        isWeekday = 1\n",
    "    elif \"화요일\" in d:\n",
    "        promise_week = 1\n",
    "        isWeekday = 1\n",
    "    elif \"수요일\" in d :\n",
    "        promise_week = 2\n",
    "        isWeekday = 1\n",
    "    elif \"목요일\" in d: \n",
    "        promise_week = 3\n",
    "        isWeekday = 1\n",
    "    elif \"금요일\" in d:\n",
    "        promise_week = 4\n",
    "        isWeekday = 1\n",
    "    elif \"토요일\" in d:\n",
    "        promise_week = 5\n",
    "        isWeekday = 1\n",
    "    elif \"일요일\" in d:\n",
    "        promise_week = 5\n",
    "        isWeekday = 1\n",
    "    elif \"일\" in d and re.search('\\d',d):\n",
    "        day = re.sub(r'[^0-9]', '', d)\n",
    "        date_fix = 1\n",
    "    elif \"월\" in d and re.search('\\d',d):\n",
    "        month = re.sub(r'[^0-9]', '', d)\n",
    "    elif \"년\" in d and re.search('\\d',d):\n",
    "        year = re.sub(r'[^0-9]', '', d)\n",
    "        if year < 2023:\n",
    "            year = 2023\n",
    "\n",
    "#대화에 요일이 있을 때\n",
    "if isWeekday==1:\n",
    "    if weekday > promise_week or next_week == 1:\n",
    "        day = int(now.day) + promise_week - weekday + 7\n",
    "    else:\n",
    "        day = int(now.day) + promise_week - weekday\n",
    "    weekday = promise_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b158b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first확률에서 약속장소가 없을경우 두번때 확률까지 탐색\n",
    "# second_loc = []\n",
    "# if loc == []:\n",
    "#     for i,wp in enumerate(zip(lines, for_loc_list)):\n",
    "#                 date_time[i] = []\n",
    "#                 for j,(word, p) in enumerate(zip(wp[0], wp[1])):\n",
    "#                     #B-I를 같은 리스트에 담아서 연결성 up    ex) 내일 오전 어떠세요? 10시 좋아요\n",
    "#                     if p == 'DAT-B':\n",
    "#                         date.append(word)\n",
    "#                         date_time[i].append(word)\n",
    "#                     elif p == 'DAT-I':\n",
    "#                         date.append(word)\n",
    "#                         date_time[i].append(word)\n",
    "#                     elif p == 'TIM-B':\n",
    "#                         time.append(word)\n",
    "#                         date_time[i].append(word)\n",
    "#                     elif p == 'TIM-I':\n",
    "#                         time.append(word)\n",
    "#                         date_time[i].append(word)\n",
    "#                     elif p == 'LOC-B':\n",
    "#                         if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "#                             second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "#                         else:\n",
    "#                             second_loc.append(word)\n",
    "#                     elif p == 'LOC-I':\n",
    "#                         second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "#                     elif p == 'ORG-B':\n",
    "#                         if preds_list[i][j-1] in ['ORG-B','LOC-B'] and loc != []:\n",
    "#                             second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "#                         else:\n",
    "#                             second_loc.append(word)\n",
    "#                     elif p == 'ORG-I':\n",
    "#                         second_loc[-1] = second_loc[-1] + \" \"+ word\n",
    "#                     elif (p == 'NUM-B'or p == 'NUM-I')and \"시\" in word:\n",
    "#                         time.append(word)\n",
    "#                         date_time[i].append(word)\n",
    "#                     elif \"반\" in word and preds_list[i][j-1] in ['TIM-B','TIM-I']:\n",
    "#                         time.append(word)\n",
    "#     loc = second_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f373b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loc == []:\n",
    "    location = \"미정\"\n",
    "else:\n",
    "    location = loc[-1]\n",
    "\n",
    "if day == now.day:\n",
    "    if int(hour) < now.hour:\n",
    "        hour = int(hour) + 12\n",
    "if next_day == 1 :\n",
    "    if 0 < int(hour) < 6:\n",
    "        hour = int(hour) + 12\n",
    "weekday = weekday % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "132fb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = -1\n",
    "max = -1\n",
    "for i in range(len(date_time)):\n",
    "    if max <= len(date_time[i]):\n",
    "        max = len(date_time[i])\n",
    "        max_i = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "870dd570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주요 통화 내용 : 두 세시 네 두 세시 될 것 같습니다. \n"
     ]
    }
   ],
   "source": [
    "print(\"주요 통화 내용 : {} \".format(' '.join(s for s in lines[max_i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5f63b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "약속 장소 : 한양대 에리카 , 약속 시간 : 2023년 2월 6일  15시 0분 (월요일)\n"
     ]
    }
   ],
   "source": [
    "print(\"약속 장소 : {} , 약속 시간 : {}년 {}월 {}일  {}시 {}분 ({})\".format(location,year,month,day,hour,minute,WEEKDAY[weekday]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3c128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dae02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15671e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c0035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe625d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfae677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f9a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9162af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c94d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cebc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
